# Métricas de Avaliação

Métricas de Avaliação são indicadores utilizados para medir a qualidade e a precisão de modelos de Inteligencia Artificial. Essas métricas fornecem dados do modelo frente a novos dados, isso é, dados que não foram usados na fase de treino do modelo.

Além disso, essas métricas podem ser utilizadas para comparar diferentes modelos e detectar problemas como **overfiting** e **underfiting**.

**TÓPICOS ABORDADOS**

- [Erro Absoluto Médio (MAE)](mean_absolute_error.ipynb)
- [Erro Quadrático Médio (MSE)](mean_squared_error.ipynb)
- [Raiz do Erro Quadrático Médio (RMSE)](root_mean_squared_error.ipynb)
 
---  

# Dataset de teste

Como métricas de Avaliação são utilizadas para medir o desempenho de modelos de IA não seram utilizados datasets especificos para o estudo dessas métricas, sendo que, cada métrica abordada vai utilizar um dataset que melhor se encaixa no modelo que será avaliado.

Dessa forma, para cada modelo apresentado nesse diretório será utilizado um conjunto de dados diferentes. Os dados pré-definidos podem ser encontrados na pasta [Data](../Data/) desse repositório, porém, em algums casos será utilizado um bloco de código dedicado a gerar dados que melhor se adequam ao contexto apresentado.

---

[<- Anterior](../Modelos/Regressao/elasticnetregression.ipynb) | [Próximo ->](mean_absolute_error.ipynb)